---
layout: single
title: Research
permalink: /research/
author_profile: true
classes: wide
---

## Research Overview

My research focuses on enabling **robust physical interaction** for robots operating in uncertain and unstructured environments. I develop **multimodal tactile sensing systems**, compliant robotic interfaces, and learning-based perception methods that allow robots to interpret contact, adapt to uncertainty, and perform contact-rich tasks reliably.

---

## Multimodal Tactile Perception for Contact-Rich Manipulation

I design tactile sensing systems that combine **optical deformation sensing, vibration, and acoustic cues** to infer contact state, interaction events, and manipulation outcomes. These systems are designed to be compact and deployable, while providing rich signals for learning-based inference.

### Selected Projects: VisTac, VibTac, TacScope

<div class="grid__wrapper">

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/vistac/1.jpg" alt="VisTac overview" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/vibtac/1.jpg" alt="VibTac setup" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/tacscope/1.jpg" alt="TacScope prototype" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

</div>

### Videos

<div class="grid__wrapper">

  <div class="grid__item">
    <article class="archive__item">
      <div style="position:relative; padding-bottom:56.25%; height:0; overflow:hidden; border-radius:12px;">
        <iframe
          src="https://www.youtube.com/embed/VIDEO_ID_1"
          title="VisTac demo video"
          style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen>
        </iframe>
      </div>
      <p style="margin-top:8px;"><strong>VisTac:</strong> controllable-transparency tactile/vision sensing for manipulation.</p>
    </article>
  </div>

  <div class="grid__item">
    <article class="archive__item">
      <div style="position:relative; padding-bottom:56.25%; height:0; overflow:hidden; border-radius:12px;">
        <iframe
          src="https://www.youtube.com/embed/VIDEO_ID_2"
          title="VibTac demo video"
          style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen>
        </iframe>
      </div>
      <p style="margin-top:8px;"><strong>VibTac:</strong> high-bandwidth multimodal tactile perception using vision, vibration, and audio.</p>
    </article>
  </div>

</div>

---

## Compliant and Bio-Inspired Interfaces for Embodied Sensing

I explore bio-inspired and compliant robotic interfaces that couple **mechanical morphology with sensing**, reducing reliance on precise models and enabling robust interaction in uncertain environments. A central theme is whisker- and fiber-inspired sensing for contact and flow.

### Selected Project: FibTac

<div class="grid__wrapper">

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/fibtac/1.jpg" alt="FibTac gripper overview" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/fibtac/2.jpg" alt="FibTac underwater interaction" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

  <div class="grid__item">
    <article class="archive__item">
      <div class="archive__item-teaser">
        <img src="/images/research/fibtac/3.jpg" alt="FibTac flow sensing" style="width:100%; height:220px; object-fit:cover; border-radius:10px;">
      </div>
    </article>
  </div>

</div>

### Video

<div style="max-width: 980px;">
  <div style="position:relative; padding-bottom:56.25%; height:0; overflow:hidden; border-radius:12px;">
    <iframe
      src="https://www.youtube.com/embed/VIDEO_ID_3"
      title="FibTac demo video"
      style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      allowfullscreen>
    </iframe>
  </div>
  <p style="margin-top:8px;"><strong>FibTac:</strong> fiber-based embodied sensing for contact, flow, and granular interaction.</p>
</div>

---

## Learning-Enabled Sensor Fusion and Robust Inference

Across these platforms, I develop learning-based methods that fuse multimodal signals to improve robustness in the presence of occlusion, noise, and partial observability. My long-term goal is to develop tactile intelligence that generalizes across tasks, objects, and environments.

For related publications, please see  
➡️ **[Publications](/publications/)**.
