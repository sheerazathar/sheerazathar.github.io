---
layout: single
title: Research
permalink: /research/
author_profile: true
---

## Research Overview

My research focuses on enabling **robust, intelligent physical interaction** for robots operating in complex, uncertain, and unstructured environments. I am particularly interested in how **multimodal sensing, compliant mechanical design, and learning-based perception** can be integrated to allow robots to perceive, reason about, and interact with the physical world in a human-compatible manner.

Robotic systems increasingly operate outside structured factory settings—engaging in tasks such as manipulation, exploration, grasping, and interaction in contact-rich environments. In these settings, **vision alone is insufficient**. My work addresses this gap by developing **novel tactile, acoustic, and vision-based sensing systems**, alongside perception and learning frameworks that exploit these complementary modalities.

My research is inherently interdisciplinary and draws from **robotics, soft mechanics, perception, and machine learning**, with applications spanning **manipulation, underwater robotics, and embodied intelligence**.

---

## Research Thrusts

### Multimodal Tactile Perception for Contact-Rich Manipulation

A central theme of my research is the development of **multimodal tactile sensing systems** that enable robots to detect, localize, and interpret physical interactions with their environment.

I have developed a series of sensing platforms that combine **vision-based tactile sensing, vibration, and acoustic signals** to capture rich contact information during manipulation tasks. These sensors are designed to be **low-cost, compact, and easily deployable**, while still providing high-fidelity signals for learning-based perception.

Key contributions in this thrust include:
- Vision-based tactile sensing using elastomer deformation and controllable transparency
- Acoustic and vibration-based contact detection for event recognition
- Learning-based fusion of heterogeneous sensory streams for robust inference

This line of work enables robots to go beyond binary contact detection and toward **interpretable, fine-grained understanding of physical interaction events**.

---

### Compliant and Bio-Inspired Robotic Interfaces

Another core focus of my research is the design of **compliant, bio-inspired robotic interfaces** that improve safety, adaptability, and robustness during interaction.

Inspired by biological whiskers, fibers, and soft tissues, I explore sensing and actuation mechanisms that exploit **mechanical compliance as a feature rather than a limitation**. These designs allow robots to safely interact with fragile objects, uncertain surfaces, and deformable environments.

Representative directions include:
- Fiber- and whisker-inspired tactile sensing for flow and contact perception
- Variable-stiffness structures for adaptive grasping and manipulation
- Soft and hybrid mechanisms that couple sensing with mechanical intelligence

By co-designing **mechanics and sensing**, this work aims to reduce reliance on precise models and instead leverage physical embodiment for perception.

---

### Learning-Enabled Perception and Sensor Fusion

Modern robotic systems must reason under uncertainty, partial observability, and noisy sensory inputs. My research addresses this challenge through **learning-based perception frameworks** that integrate multimodal sensory data.

I develop models that combine:
- Visual cues from tactile and external cameras
- Temporal acoustic and vibration signals
- Contextual task and motion information

These models are designed to support tasks such as **contact event detection, state estimation, and interaction classification**, particularly in scenarios where individual modalities fail.

An important emphasis of this work is **robustness and generalization**—ensuring that learned models transfer across objects, tasks, and environments.

---

### Applications in Underwater and Field Robotics

Many real-world robotic applications occur in environments where sensing is degraded by lighting, turbidity, noise, or flow disturbances. I am actively exploring how multimodal tactile and acoustic sensing can enable **reliable perception in underwater and field settings**.

Ongoing and future efforts include:
- Flow-aware tactile sensing for underwater robots
- Perception-driven compliant grippers for aquatic manipulation
- Sensor fusion strategies for low-visibility environments

These applications provide a testbed for developing sensing systems that operate beyond laboratory conditions.

---

## Research Philosophy and Future Directions

My research philosophy emphasizes **tight integration between sensing, mechanics, and learning**, rather than treating them as isolated components. I believe that many challenges in robotic interaction can be addressed by designing systems where **physical embodiment and perception are co-optimized**.

Looking forward, I am interested in:
- Scaling multimodal tactile sensing to whole-hand and whole-body interaction
- Exploring foundation models for physical interaction understanding
- Applying these ideas to assistive, underwater, and human-centered robotics

Through this work, I aim to contribute toward robotic systems that are **more perceptive, adaptable, and capable of operating safely in the real world**.

---

For a detailed list of publications, please see the  
➡️ **[Publications](/publications/)** page.
